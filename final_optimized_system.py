#!/usr/bin/env python3

import sys
import json
import numpy as np
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, ExtraTreesRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import cross_val_score
import warnings
warnings.filterwarnings('ignore')

class FinalOptimizedReimbursementSystem:
    """
    Final optimized implementation of the multi-layered business rule engine
    Combines all insights from interviews and data analysis for maximum accuracy
    """
    
    def __init__(self):
        self.scaler = RobustScaler()
        self.ensemble = None
        self.specialized_models = {}
        self.is_trained = False
    
    def engineer_comprehensive_features(self, X):
        """Comprehensive feature engineering based on all analysis layers"""
        days = X[:, 0]
        miles = X[:, 1] 
        receipts = X[:, 2]
        
        # === LAYER 1: BASE CALCULATION FEATURES ===
        efficiency = np.divide(miles, days, out=np.zeros_like(miles), where=days!=0)
        daily_spending = np.divide(receipts, days, out=np.zeros_like(receipts), where=days!=0)
        miles_per_dollar = np.divide(miles, np.maximum(receipts, 1))
        total_trip_value = days * miles * receipts / 10000  # Normalized complexity
        
        # === LAYER 2: EFFICIENCY ASSESSMENT FEATURES ===
        # Kevin's efficiency tiers with exact thresholds
        is_kevin_optimal = ((efficiency >= 180) & (efficiency <= 220)).astype(float)
        is_high_efficiency = (efficiency >= 200).astype(float)
        is_low_efficiency = (efficiency < 30).astype(float)
        is_medium_efficiency = ((efficiency >= 50) & (efficiency < 150)).astype(float)
        
        # Efficiency bonuses/penalties
        efficiency_bonus_factor = np.where(is_kevin_optimal, 1.15, 
                                 np.where(is_high_efficiency, 1.08,
                                 np.where(is_low_efficiency, 0.9, 1.0)))
        
        # === LAYER 3: TRIP CATEGORIZATION FEATURES ===
        # Jennifer's sweet spot insights
        is_short_trip = (days <= 2).astype(float)
        is_sweet_spot = ((days >= 4) & (days <= 6)).astype(float)
        is_medium_trip = ((days >= 3) & (days <= 7)).astype(float)
        is_long_trip = (days >= 8).astype(float)
        is_very_long_trip = (days >= 12).astype(float)
        
        # Trip length multipliers based on interview insights
        trip_length_factor = np.where(is_sweet_spot, 1.05,
                            np.where(is_short_trip, 1.1,
                            np.where(is_long_trip, 0.92,
                            np.where(is_very_long_trip, 0.85, 1.0))))
        
        # === LAYER 4: RECEIPT PROCESSING FEATURES ===
        # Lisa's accounting insights about receipt tiers
        is_small_receipts = (receipts < 100).astype(float)
        is_medium_receipts = ((receipts >= 500) & (receipts <= 1500)).astype(float)
        is_high_receipts = (receipts > 1500).astype(float)
        is_very_high_receipts = (receipts > 2000).astype(float)
        
        # Receipt penalties and bonuses
        small_receipt_penalty = ((receipts > 0) & (receipts < 30) & (days > 1)).astype(float)
        receipt_tier_bonus = np.where(is_medium_receipts, 1.05,
                           np.where(is_high_receipts, 0.85,
                           np.where(is_very_high_receipts, 0.75, 1.0)))
        
        # === LAYER 5: TEMPORAL/CONTEXTUAL PROXY FEATURES ===
        # Pseudo-temporal features (Marcus's seasonal observations)
        pseudo_quarter = (np.array([hash(int(r * 100)) % 4 for r in receipts])).astype(float)
        pseudo_month = (np.array([hash((int(d), int(m))) % 12 for d, m in zip(days, miles)])).astype(float)
        pseudo_submission_day = ((days + miles) % 7).astype(float)
        
        # Employee/department proxies
        employee_type_proxy = (np.array([hash((int(e * 10), int(ds))) % 5 for e, ds in zip(efficiency, daily_spending)])).astype(float)
        
        # === LAYER 6: LEGACY QUIRKS FEATURES ===
        # Lisa's rounding quirks
        has_49_cents = ((receipts * 100) % 100 == 49).astype(float)
        has_99_cents = ((receipts * 100) % 100 == 99).astype(float)
        has_rounding_quirk = ((has_49_cents + has_99_cents) > 0).astype(float)
        
        # Mileage threshold effects
        near_100_miles = (np.abs(miles - 100) < 10).astype(float)
        near_500_miles = (np.abs(miles - 500) < 25).astype(float)
        near_1000_miles = (np.abs(miles - 1000) < 50).astype(float)
        
        # === SPECIFIC BUSINESS RULES ===
        # Kevin's sweet spot combo
        kevin_sweet_spot = ((days == 5) & (efficiency >= 180) & (daily_spending < 100)).astype(float)
        
        # Marcus's vacation penalty
        vacation_penalty = ((days >= 8) & (daily_spending > 150)).astype(float)
        
        # Five day bonus (Lisa confirmed)
        five_day_bonus = (days == 5).astype(float)
        
        # Spending threshold violations (Kevin's analysis)
        exceeds_short_spending = ((days <= 3) & (daily_spending > 75)).astype(float)
        exceeds_medium_spending = ((days >= 4) & (days <= 6) & (daily_spending > 120)).astype(float)
        exceeds_long_spending = ((days >= 7) & (daily_spending > 90)).astype(float)
        
        # === ADVANCED INTERACTION FEATURES ===
        efficiency_spending_ratio = efficiency / np.maximum(daily_spending, 1)
        days_miles_receipts_interaction = np.log1p(days * miles * receipts)
        balanced_trip_indicator = ((days >= 4) & (days <= 6) & (efficiency >= 50) & (efficiency <= 150) & (daily_spending >= 50) & (daily_spending <= 120)).astype(float)
        
        # High-value indicators
        high_value_short = ((days <= 3) & (miles > 300) & (receipts > 200)).astype(float)
        low_cost_efficient = ((daily_spending < 75) & (efficiency > 100)).astype(float)
        
        # === POLYNOMIAL AND TRANSFORMATION FEATURES ===
        days_squared = days ** 2
        miles_squared = miles ** 2
        receipts_squared = receipts ** 2
        efficiency_squared = efficiency ** 2
        
        log_days = np.log1p(days)
        log_miles = np.log1p(miles)
        log_receipts = np.log1p(receipts)
        log_efficiency = np.log1p(efficiency)
        
        sqrt_days = np.sqrt(days)
        sqrt_miles = np.sqrt(miles)
        sqrt_receipts = np.sqrt(receipts)
        sqrt_efficiency = np.sqrt(np.maximum(efficiency, 0))
        
        # === COMBINE ALL FEATURES ===
        features = np.column_stack([
            # Base inputs
            days, miles, receipts,
            
            # Layer 1: Base calculations
            efficiency, daily_spending, miles_per_dollar, total_trip_value,
            
            # Layer 2: Efficiency assessment
            is_kevin_optimal, is_high_efficiency, is_low_efficiency, is_medium_efficiency,
            efficiency_bonus_factor,
            
            # Layer 3: Trip categorization
            is_short_trip, is_sweet_spot, is_medium_trip, is_long_trip, is_very_long_trip,
            trip_length_factor,
            
            # Layer 4: Receipt processing
            is_small_receipts, is_medium_receipts, is_high_receipts, is_very_high_receipts,
            small_receipt_penalty, receipt_tier_bonus,
            
            # Layer 5: Temporal/contextual
            pseudo_quarter, pseudo_month, pseudo_submission_day, employee_type_proxy,
            
            # Layer 6: Legacy quirks
            has_49_cents, has_99_cents, has_rounding_quirk,
            near_100_miles, near_500_miles, near_1000_miles,
            
            # Specific business rules
            kevin_sweet_spot, vacation_penalty, five_day_bonus,
            exceeds_short_spending, exceeds_medium_spending, exceeds_long_spending,
            
            # Advanced interactions
            efficiency_spending_ratio, days_miles_receipts_interaction, balanced_trip_indicator,
            high_value_short, low_cost_efficient,
            
            # Polynomial and transformations
            days_squared, miles_squared, receipts_squared, efficiency_squared,
            log_days, log_miles, log_receipts, log_efficiency,
            sqrt_days, sqrt_miles, sqrt_receipts, sqrt_efficiency
        ])
        
        return features
    
    def apply_business_rule_postprocessing(self, prediction, days, miles, receipts):
        """Apply final business rule adjustments"""
        efficiency = miles / max(days, 1)
        daily_spending = receipts / max(days, 1)
        
        # Kevin's sweet spot combo (strongest signal from interviews)
        if days == 5 and efficiency >= 180 and daily_spending < 100:
            prediction *= 1.15
        
        # Five day bonus (Lisa confirmed, multiple sources)
        if days == 5:
            prediction += 30.0
        
        # Marcus's vacation penalty
        if days >= 8 and daily_spending > 150:
            prediction *= 0.88
        
        # Lisa's rounding quirk (accounting artifact)
        if receipts > 0:
            cents = int((receipts * 100) % 100)
            if cents == 49 or cents == 99:
                prediction += 18.0
        
        # Kevin's efficiency bonuses
        if 180 <= efficiency <= 220:
            prediction += 40.0
        elif efficiency >= 300:
            prediction += 25.0
        elif efficiency < 20 and days > 1:
            prediction -= 25.0
        
        # Small receipt penalty (Dave and Lisa confirmed)
        if 0 < receipts < 30 and days > 1:
            prediction -= 30.0
        
        # Trip length adjustments
        if days <= 2:
            prediction += 35.0  # Short trip bonus
        elif days >= 12:
            penalty = (days - 11) * 15
            prediction -= penalty
        
        # Ensure reasonable bounds
        min_reasonable = days * 40.0  # Minimum per day
        max_reasonable = days * 450 + miles * 1.5 + receipts * 1.0
        prediction = max(min_reasonable, min(prediction, max_reasonable))
        
        return prediction
    
    def load_data(self, filepath='public_cases.json'):
        """Load training data"""
        with open(filepath, 'r') as f:
            data = json.load(f)
        
        X = []
        y = []
        for case in data:
            inp = case['input']
            X.append([inp['trip_duration_days'], inp['miles_traveled'], inp['total_receipts_amount']])
            y.append(case['expected_output'])
        
        return np.array(X), np.array(y)
    
    def train_optimized_ensemble(self, X, y):
        """Train the final optimized ensemble"""
        print("Training final optimized business rule engine...")
        
        # Engineer comprehensive features
        X_features = self.engineer_comprehensive_features(X)
        X_scaled = self.scaler.fit_transform(X_features)
        
        # Create multiple diverse models optimized for different aspects
        models = [
            # Gradient boosting variants (best for exact matches)
            ('gb_exact', GradientBoostingRegressor(
                n_estimators=400, max_depth=6, learning_rate=0.05, 
                subsample=0.9, random_state=42, loss='absolute_error'
            )),
            ('gb_robust', GradientBoostingRegressor(
                n_estimators=300, max_depth=8, learning_rate=0.08, 
                subsample=0.85, random_state=43, loss='huber'
            )),
            
            # Random forest variants
            ('rf_deep', RandomForestRegressor(
                n_estimators=250, max_depth=20, min_samples_split=2,
                min_samples_leaf=1, random_state=42
            )),
            ('extra_trees', ExtraTreesRegressor(
                n_estimators=200, max_depth=15, min_samples_split=3,
                random_state=42
            )),
            
            # Neural network for complex patterns
            ('mlp', MLPRegressor(
                hidden_layer_sizes=(128, 64, 32), activation='relu',
                max_iter=500, random_state=42, early_stopping=True
            )),
            
            # Linear models for regularization
            ('ridge', Ridge(alpha=0.1)),
            ('lasso', Lasso(alpha=0.1, max_iter=2000))
        ]
        
        # Weight models based on cross-validation performance for exact matches
        print("Evaluating model performance...")
        weights = []
        for name, model in models:
            try:
                # Use absolute error for exact match optimization
                scores = cross_val_score(model, X_scaled, y, cv=3, scoring='neg_mean_absolute_error')
                weight = -scores.mean()  # Convert to positive (lower error = higher weight)
                weights.append(1.0 / max(weight, 1.0))  # Inverse weight
                print(f"{name}: MAE = ${-scores.mean():.2f}")
            except:
                weights.append(0.1)  # Low weight for failed models
        
        # Normalize weights
        total_weight = sum(weights)
        weights = [w / total_weight * len(weights) for w in weights]
        
        # Create weighted ensemble
        self.ensemble = VotingRegressor(estimators=models, weights=weights)
        self.ensemble.fit(X_scaled, y)
        
        self.is_trained = True
        
        # Evaluate training performance
        predictions = []
        for i, features in enumerate(X):
            pred = self.predict(features[0], features[1], features[2])
            predictions.append(pred)
        
        predictions = np.array(predictions)
        exact_matches = np.sum(np.abs(predictions - y) < 0.01)
        very_close_matches = np.sum(np.abs(predictions - y) < 0.10)
        close_matches = np.sum(np.abs(predictions - y) < 1.0)
        avg_error = np.mean(np.abs(predictions - y))
        
        print(f"\nðŸŽ¯ Final Optimized System Performance:")
        print(f"  Exact matches (Â±$0.01): {exact_matches}/{len(y)} ({exact_matches/len(y)*100:.1f}%)")
        print(f"  Very close (Â±$0.10): {very_close_matches}/{len(y)} ({very_close_matches/len(y)*100:.1f}%)")
        print(f"  Close matches (Â±$1.00): {close_matches}/{len(y)} ({close_matches/len(y)*100:.1f}%)")
        print(f"  Average error: ${avg_error:.2f}")
        
        return {
            'exact_matches': exact_matches,
            'very_close_matches': very_close_matches,
            'close_matches': close_matches,
            'avg_error': avg_error
        }
    
    def predict(self, days, miles, receipts):
        """Make optimized prediction"""
        if not self.is_trained:
            raise ValueError("Model must be trained first")
        
        # Prepare features
        X = np.array([[days, miles, receipts]])
        X_features = self.engineer_comprehensive_features(X)
        X_scaled = self.scaler.transform(X_features)
        
        # Get ensemble prediction
        prediction = self.ensemble.predict(X_scaled)[0]
        
        # Apply business rule postprocessing
        final_prediction = self.apply_business_rule_postprocessing(prediction, days, miles, receipts)
        
        return round(max(0, final_prediction), 2)

# Global optimized system instance
_optimized_system = None

def get_optimized_system():
    global _optimized_system
    if _optimized_system is None:
        _optimized_system = FinalOptimizedReimbursementSystem()
        X, y = _optimized_system.load_data()
        _optimized_system.train_optimized_ensemble(X, y)
    return _optimized_system

if __name__ == "__main__":
    if len(sys.argv) != 4:
        print("Usage: python3 final_optimized_system.py <trip_duration_days> <miles_traveled> <total_receipts_amount>")
        sys.exit(1)
    
    try:
        system = get_optimized_system()
        
        trip_duration = float(sys.argv[1])
        miles = float(sys.argv[2])
        receipts = float(sys.argv[3])
        
        result = system.predict(trip_duration, miles, receipts)
        print(result)
    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)